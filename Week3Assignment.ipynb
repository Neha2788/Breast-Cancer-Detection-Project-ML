{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Breast-Cancer-Detection-using-Machine-Learning-master\\cancer dataset.csv\")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y=LabelEncoder()\n",
    "df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     fractal_dimension_mean  ...  fractal_dimension_se  radius_worst  \\\n",
      "0                   0.07871  ...              0.006193        25.380   \n",
      "1                   0.05667  ...              0.003532        24.990   \n",
      "2                   0.05999  ...              0.004571        23.570   \n",
      "3                   0.09744  ...              0.009208        14.910   \n",
      "4                   0.05883  ...              0.005115        22.540   \n",
      "..                      ...  ...                   ...           ...   \n",
      "564                 0.05623  ...              0.004239        25.450   \n",
      "565                 0.05533  ...              0.002498        23.690   \n",
      "566                 0.05648  ...              0.003892        18.980   \n",
      "567                 0.07016  ...              0.006185        25.740   \n",
      "568                 0.05884  ...              0.002783         9.456   \n",
      "\n",
      "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0            17.33           184.60      2019.0           0.16220   \n",
      "1            23.41           158.80      1956.0           0.12380   \n",
      "2            25.53           152.50      1709.0           0.14440   \n",
      "3            26.50            98.87       567.7           0.20980   \n",
      "4            16.67           152.20      1575.0           0.13740   \n",
      "..             ...              ...         ...               ...   \n",
      "564          26.40           166.10      2027.0           0.14100   \n",
      "565          38.25           155.00      1731.0           0.11660   \n",
      "566          34.12           126.70      1124.0           0.11390   \n",
      "567          39.42           184.60      1821.0           0.16500   \n",
      "568          30.37            59.16       268.6           0.08996   \n",
      "\n",
      "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \n",
      "0              0.66560           0.7119                0.2654          0.4601  \n",
      "1              0.18660           0.2416                0.1860          0.2750  \n",
      "2              0.42450           0.4504                0.2430          0.3613  \n",
      "3              0.86630           0.6869                0.2575          0.6638  \n",
      "4              0.20500           0.4000                0.1625          0.2364  \n",
      "..                 ...              ...                   ...             ...  \n",
      "564            0.21130           0.4107                0.2216          0.2060  \n",
      "565            0.19220           0.3215                0.1628          0.2572  \n",
      "566            0.30940           0.3403                0.1418          0.2218  \n",
      "567            0.86810           0.9387                0.2650          0.4087  \n",
      "568            0.06444           0.0000                0.0000          0.2871  \n",
      "\n",
      "[569 rows x 29 columns]\n",
      "0      M\n",
      "1      M\n",
      "2      M\n",
      "3      M\n",
      "4      M\n",
      "      ..\n",
      "564    M\n",
      "565    M\n",
      "566    M\n",
      "567    M\n",
      "568    B\n",
      "Name: diagnosis, Length: 569, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,2:31] #features that help us determine if patient has cancer or not\n",
    "print(X)\n",
    "Y=df.iloc[:,1] #this is the dataset containing our target variable which indicates diagnosis\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     fractal_dimension_mean  ...  fractal_dimension_se  radius_worst  \\\n",
      "0                   0.07871  ...              0.006193        25.380   \n",
      "1                   0.05667  ...              0.003532        24.990   \n",
      "2                   0.05999  ...              0.004571        23.570   \n",
      "3                   0.09744  ...              0.009208        14.910   \n",
      "4                   0.05883  ...              0.005115        22.540   \n",
      "..                      ...  ...                   ...           ...   \n",
      "564                 0.05623  ...              0.004239        25.450   \n",
      "565                 0.05533  ...              0.002498        23.690   \n",
      "566                 0.05648  ...              0.003892        18.980   \n",
      "567                 0.07016  ...              0.006185        25.740   \n",
      "568                 0.05884  ...              0.002783         9.456   \n",
      "\n",
      "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0            17.33           184.60      2019.0           0.16220   \n",
      "1            23.41           158.80      1956.0           0.12380   \n",
      "2            25.53           152.50      1709.0           0.14440   \n",
      "3            26.50            98.87       567.7           0.20980   \n",
      "4            16.67           152.20      1575.0           0.13740   \n",
      "..             ...              ...         ...               ...   \n",
      "564          26.40           166.10      2027.0           0.14100   \n",
      "565          38.25           155.00      1731.0           0.11660   \n",
      "566          34.12           126.70      1124.0           0.11390   \n",
      "567          39.42           184.60      1821.0           0.16500   \n",
      "568          30.37            59.16       268.6           0.08996   \n",
      "\n",
      "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \n",
      "0              0.66560           0.7119                0.2654          0.4601  \n",
      "1              0.18660           0.2416                0.1860          0.2750  \n",
      "2              0.42450           0.4504                0.2430          0.3613  \n",
      "3              0.86630           0.6869                0.2575          0.6638  \n",
      "4              0.20500           0.4000                0.1625          0.2364  \n",
      "..                 ...              ...                   ...             ...  \n",
      "564            0.21130           0.4107                0.2216          0.2060  \n",
      "565            0.19220           0.3215                0.1628          0.2572  \n",
      "566            0.30940           0.3403                0.1418          0.2218  \n",
      "567            0.86810           0.9387                0.2650          0.4087  \n",
      "568            0.06444           0.0000                0.0000          0.2871  \n",
      "\n",
      "[569 rows x 29 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n",
      "Name: diagnosis, Length: 569, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Breast-Cancer-Detection-using-Machine-Learning-master\\cancer dataset.csv\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y=LabelEncoder()\n",
    "df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)\n",
    "df\n",
    "X=df.iloc[:,2:31] #features that help us determine if patient has cancer or not\n",
    "print(X)\n",
    "Y=df.iloc[:,1] #this is the dataset containing our target variable which indicates diagnosis\n",
    "print(Y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.25, random_state = 0)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.65079907 -0.43057322 -0.68024847 ... -0.69592933 -0.36433881\n",
      "   0.32349851]\n",
      " [-0.82835341  0.15226547 -0.82773762 ... -1.29277423 -1.45036679\n",
      "   0.62563098]\n",
      " [ 1.68277234  2.18977235  1.60009756 ...  0.26255563  0.72504581\n",
      "  -0.51329768]\n",
      " ...\n",
      " [-1.33114223 -0.22172269 -1.3242844  ... -0.78274313 -0.98806491\n",
      "  -0.69995543]\n",
      " [-1.25110186 -0.24600763 -1.28700242 ... -1.36015587 -1.75887319\n",
      "  -1.56206114]\n",
      " [-0.74662205  1.14066273 -0.72203706 ...  0.47201917 -0.2860679\n",
      "  -1.24094654]]\n",
      "[[-0.1839902   0.22170989 -0.11761404 ...  0.97465513  1.40089716\n",
      "   1.16977773]\n",
      " [-0.23927557  1.20953909 -0.30776593 ... -0.59768168 -0.79588429\n",
      "  -0.81775175]\n",
      " [-0.00358531 -0.79326895 -0.07782455 ... -0.92095006 -0.46102846\n",
      "  -1.35426278]\n",
      " ...\n",
      " [-0.49242436 -1.50124802 -0.52388569 ... -0.42800809 -0.0848268\n",
      "   0.34236625]\n",
      " [-0.14616337 -1.77900972 -0.14818913 ... -0.82451961 -0.58355147\n",
      "  -0.35440132]\n",
      " [ 1.61714893 -0.27324893  1.6440133  ...  1.69566211  1.69773906\n",
      "   1.27080903]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Now, there is a small homework for statistics wherein you have to read about the parameteres, define them in brief and write about two main types of distributions:\n",
    "#### 1. Gaussian distribution\n",
    "#### 2. Binomial distribution\n",
    "#### Differentiate between both as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters - \n",
    "It is the population mean, that is conclusion is made on the basis of entire set of data. Unlike in statistic conclusion is made on the basis of some sample of data, so accuracy rate is low and it will vary on the basis of samples selected. \n",
    "But if parameters are considered the accuracy rate is high and it never changes as whole dataset is considered to determine conclusion.\n",
    "\n",
    "e.g - If in a company of 150 workers, 20% of workeres were paid greater than 200000 per annum, here payroll data of every worker is known that is whole data is considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian distribution is a special type of curve which is bell shape and used for most of the dataset so also called as Bell Curve or Normal distribution\n",
    "It has tendency that data clusters around the central value and the central value is also known as Mean(μ)\n",
    "So for all the normal distribution some data values fall below the mean and few fall above the mean but most of the data values are clustered near the mean.\n",
    "e.g exam score  - Few students get good grades and few got failed but most of the students got the average score, that means most of the score clustered around the mean (central value)\n",
    "\n",
    "The cure is symmetric around the mean that means Exactly half of the values are to the left of the center and the other half to the right.\n",
    "\n",
    "Guassian distribution is based on two values i.e Mean (μ) and Standard deviation (σ)\n",
    "\n",
    "Mean (μ) - It Charaterize the position of the normal distribution\n",
    "As mean increases the graph moves towards right and as mean decreases the graph moves towards left\n",
    "\n",
    "Standared deviation (σ) - charectrizes the spread of the normal distribution\n",
    "spread increases curve becames flatter and spread decreases curve become taller \n",
    "As the total area under the curve is 1, so the total spread will remain constant always.\n",
    "\n",
    "The mean, median and mode of the distribution coincide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial Distribution is a probability distribution that describes a likelihood of a value which would take place of either of the two independent values under a given set of parameters. \n",
    "It is discret distribution as it counts only two states namely; Success/Failure, Pass/Fail, win/Loss, head/tail etc.\n",
    "Each event is an independent event and there are only 2 possible outcomes in the event.\n",
    "Only a specific and limited number of events are conducted\n",
    "Probability for any one of the outcome remains same across all the events\n",
    "\n",
    "e.g - \n",
    "purchase of a lottery ticket which comes with two assumptions. One is that the person would win the money and the other is that they would not win the money. \n",
    "Thus the outcome could be a success or failure only. \n",
    "Also each subsequent buying of a lottery ticket is an independent event, and outcome for new ticket is independent of the outcome of previous tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference of Guassian and Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Guassian distribution is continuous where as Binomial distribution is discret\n",
    "2. There are only two possiblities in Binomial distribution unlikly in Guassian distribution\n",
    "3. Guassian distribution is always symmetrical over the mean, whereas binomial distribution may be symmetrical over mean depending on number of trials\n",
    "4. A normal distribution is highly different from Binomial Distribution. However, if the number of trials approaches infinity then the shapes will be quite similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Selectively write 5 lines about each of the above three algorithms so that even a rather inexperienced person can understand it alongwith dealing all the technicalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression :\n",
    "\n",
    "It is also called as Logit Model     \n",
    "Logistic Regression is used to find a relationship between features and probability of particular outcome.\n",
    "When the outcome of the dependent varible is discret like yes/No, 0/1, pass/fail; we use logistic regression.\n",
    "Logistic Regression is used when the dependent variable (target) is categorical.     \n",
    "\n",
    "e.g - \n",
    "     Email Spam or NOT\n",
    "     Here the outcome is already known i.e Email is spam (1) or Email is NOT spam (0)\n",
    "     In such cases the logistoic regression model is used where the outcome is binary\n",
    "     \n",
    "Also, the curve form when we plot this model is 'S-curve'\n",
    "          \n",
    "Lets take another example where age of people who opt for polices, let age be between 25-60\n",
    "So here 2 outcomes will be there - People opt for Policy (1) or People do not opt policy(0) \n",
    "to construct the model a thresold is found out (let say its age 35) which is the dividing point of this dataset, that is,        if age is above thresold (age above 35) 'People opt for policy' and if value is below threshold (age below or equal 35) 'People do Not opt for policy'\n",
    "     \n",
    "Thus we can construt 'S curve' for this dataset\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree Classifier\n",
    "\n",
    "Decision Tree, as it name says, makes decision with tree-like model. \n",
    "It splits the sample into two or more homogeneous sets (leaves) based on the most significant differentiators in your input      variables. \n",
    "To choose a differentiator, the algorithm considers all features and does a binary split on them It will then choose the        one with the highest accuracy), and repeats recursively, until it successfully splits the data in all leaves\n",
    "As we go very deep in classification it may cause overfitting of data. \n",
    "Also, decision trees can be unstable because small variations in the data might result in a completely different tree being      generated.\n",
    "e.g -\n",
    "     Decision for going to market\n",
    "\n",
    "Is there lockdown-> yes/No\n",
    "                   If yes -> dont got to market\n",
    "                    if NO -> is it raining -> yes/No\n",
    "\t\t\t\t\t\t                   if yes -> dont got to market\n",
    "\t\t\t\t\t\t                   if No -> go to market\n",
    "\n",
    "   In this way one can predict and form the decision tree for more accurate results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Random Forest classifier\n",
    "\n",
    "The random forest is a model made up of many decision trees.\n",
    "Random forest is an ensemble model that grows multiple tree and classify objects based on the “votes” of all the trees. i.e.     An object is assigned to a class that has most votes from all the trees. \n",
    "By doing so, the problem with overfitting could be     resolved.\n",
    "Reduction in over-fitting and random forest classifier is more accurate than decision trees in most cases.\n",
    "But, it is Slow real time predictor, difficult to implement, and complex algorithm.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
